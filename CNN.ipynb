{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPLEMENTATION OF CNN IN TENSORFLOW"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's develop better intuition for how Convolutional Neural Networks (CNN) work. We'll examine\n",
    "how humans classify images, and then see how CNNs use similar approaches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "# Output depth\n",
    "k_output = 64\n",
    "# Image Properties\n",
    "image_width = 10\n",
    "image_height = 10\n",
    "color_channels = 3\n",
    "# Convolution filter\n",
    "filter_size_width = 5\n",
    "filter_size_height = 5\n",
    "# Input/Image\n",
    "input = tf.placeholder(\n",
    "tf.float32,\n",
    "shape=[None, image_height, image_width, color_channels])\n",
    "# Weight and bias\n",
    "weight = tf.Variable(tf.truncated_normal(\n",
    "[filter_size_height, filter_size_width, color_channels, k_output]))\n",
    "bias = tf.Variable(tf.zeros(k_output))\n",
    "# Apply Convolution\n",
    "conv_layer = tf.nn.conv2d(input, weight, strides=[1, 2, 2, 1], padding='SAME')\n",
    "# Add bias\n",
    "conv_layer = tf.nn.bias_add(conv_layer, bias)\n",
    "# Apply activation function\n",
    "conv_layer = tf.nn.relu(conv_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_layer = tf.nn.conv2d(input, weight, strides=[1, 2, 2, 1], padding='SAME')\n",
    "conv_layer = tf.nn.bias_add(conv_layer, bias)\n",
    "conv_layer = tf.nn.relu(conv_layer)\n",
    "# Apply Max Pooling\n",
    "conv_layer = tf.nn.max_pool(\n",
    "conv_layer,\n",
    "ksize=[1, 2, 2, 1],\n",
    "strides=[1, 2, 2, 1],\n",
    "padding='SAME')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATASETS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-3-17e695df59fa>:2: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From C:\\Python\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From C:\\Python\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\base.py:252: _internal_retry.<locals>.wrap.<locals>.wrapped_fn (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use urllib or similar directly.\n",
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "WARNING:tensorflow:From C:\\Python\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting .\\train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "WARNING:tensorflow:From C:\\Python\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting .\\train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Python\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting .\\t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting .\\t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Python\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\".\", one_hot=True, reshape=False)\n",
    "import tensorflow as tf\n",
    "# Parameters\n",
    "learning_rate = 0.00001\n",
    "epochs = 1\n",
    "batch_size = 128\n",
    "# Number of samples to calculate validation and accuracy\n",
    "# Decrease this if you're running out of memory to calculate accuracy\n",
    "test_valid_size = 256\n",
    "# Network Parameters\n",
    "n_classes = 10 # MNIST total classes (0-9 digits)\n",
    "dropout = 0.75 # Dropout, probability to keep units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store layers weight & bias\n",
    "weights = {\n",
    "'wc1': tf.Variable(tf.random_normal([5, 5, 1, 32])),\n",
    "'wc2': tf.Variable(tf.random_normal([5, 5, 32, 64])),\n",
    "'wd1': tf.Variable(tf.random_normal([7*7*64, 1024])),\n",
    "'out': tf.Variable(tf.random_normal([1024, n_classes]))}\n",
    "biases = {\n",
    "'bc1': tf.Variable(tf.random_normal([32])),\n",
    "'bc2': tf.Variable(tf.random_normal([64])),\n",
    "'bd1': tf.Variable(tf.random_normal([1024])),\n",
    "'out': tf.Variable(tf.random_normal([n_classes]))}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CONVOLUTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d(x, W, b, strides=1):\n",
    "    x = tf.nn.conv2d(x, W, strides=[1, strides, strides, 1], padding='SAME')\n",
    "    x = tf.nn.bias_add(x, b)\n",
    "    return tf.nn.relu(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maxpool2d(x, k=2):\n",
    "    return tf.nn.max_pool(\n",
    "        x,\n",
    "        ksize=[1, k, k, 1],\n",
    "        strides=[1, k, k, 1],\n",
    "        padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_net(x, weights, biases, dropout):\n",
    "# Layer 1 - 28*28*1 to 14*14*32\n",
    "    conv1 = conv2d(x, weights['wc1'], biases['bc1'])\n",
    "    conv1 = maxpool2d(conv1, k=2)\n",
    "# Layer 2 - 14*14*32 to 7*7*64\n",
    "    conv2 = conv2d(conv1, weights['wc2'], biases['bc2'])\n",
    "    conv2 = maxpool2d(conv2, k=2)\n",
    "# Fully connected layer - 7*7*64 to 1024\n",
    "    fc1 = tf.reshape(conv2, [-1, weights['wd1'].get_shape().as_list()[0]])\n",
    "    fc1 = tf.add(tf.matmul(fc1, weights['wd1']), biases['bd1'])\n",
    "    fc1 = tf.nn.relu(fc1)\n",
    "    fc1 = tf.nn.dropout(fc1, dropout)\n",
    "# Output Layer - class prediction - 1024 to 10\n",
    "    out = tf.add(tf.matmul(fc1, weights['out']), biases['out'])\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TESTING ACCURACY/RESULTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  1, Batch   1 -Loss: 49919.9336 Validation Accuracy: 0.125000\n",
      "Epoch  1, Batch   2 -Loss: 37933.8516 Validation Accuracy: 0.148438\n",
      "Epoch  1, Batch   3 -Loss: 29749.4395 Validation Accuracy: 0.164062\n",
      "Epoch  1, Batch   4 -Loss: 28978.5234 Validation Accuracy: 0.160156\n",
      "Epoch  1, Batch   5 -Loss: 26227.9727 Validation Accuracy: 0.171875\n",
      "Epoch  1, Batch   6 -Loss: 23310.8281 Validation Accuracy: 0.164062\n",
      "Epoch  1, Batch   7 -Loss: 22305.2715 Validation Accuracy: 0.179688\n",
      "Epoch  1, Batch   8 -Loss: 23357.2617 Validation Accuracy: 0.171875\n",
      "Epoch  1, Batch   9 -Loss: 19099.4883 Validation Accuracy: 0.171875\n",
      "Epoch  1, Batch  10 -Loss: 20197.6660 Validation Accuracy: 0.191406\n",
      "Epoch  1, Batch  11 -Loss: 19542.8750 Validation Accuracy: 0.187500\n",
      "Epoch  1, Batch  12 -Loss: 21019.9297 Validation Accuracy: 0.175781\n",
      "Epoch  1, Batch  13 -Loss: 19555.2852 Validation Accuracy: 0.171875\n",
      "Epoch  1, Batch  14 -Loss: 21729.5430 Validation Accuracy: 0.164062\n",
      "Epoch  1, Batch  15 -Loss: 17093.7930 Validation Accuracy: 0.203125\n",
      "Epoch  1, Batch  16 -Loss: 17619.6074 Validation Accuracy: 0.203125\n",
      "Epoch  1, Batch  17 -Loss: 17470.2383 Validation Accuracy: 0.230469\n",
      "Epoch  1, Batch  18 -Loss: 15986.6270 Validation Accuracy: 0.234375\n",
      "Epoch  1, Batch  19 -Loss: 14466.4688 Validation Accuracy: 0.242188\n",
      "Epoch  1, Batch  20 -Loss: 15775.6621 Validation Accuracy: 0.253906\n",
      "Epoch  1, Batch  21 -Loss: 13263.1104 Validation Accuracy: 0.273438\n",
      "Epoch  1, Batch  22 -Loss: 15217.8896 Validation Accuracy: 0.273438\n",
      "Epoch  1, Batch  23 -Loss: 13005.9805 Validation Accuracy: 0.289062\n",
      "Epoch  1, Batch  24 -Loss: 13528.0449 Validation Accuracy: 0.289062\n",
      "Epoch  1, Batch  25 -Loss: 14195.3750 Validation Accuracy: 0.300781\n",
      "Epoch  1, Batch  26 -Loss: 12837.8574 Validation Accuracy: 0.308594\n",
      "Epoch  1, Batch  27 -Loss: 12876.7334 Validation Accuracy: 0.308594\n",
      "Epoch  1, Batch  28 -Loss: 11171.6924 Validation Accuracy: 0.316406\n",
      "Epoch  1, Batch  29 -Loss: 12981.5850 Validation Accuracy: 0.324219\n",
      "Epoch  1, Batch  30 -Loss: 14249.5352 Validation Accuracy: 0.312500\n",
      "Epoch  1, Batch  31 -Loss: 12830.8184 Validation Accuracy: 0.320312\n",
      "Epoch  1, Batch  32 -Loss: 10479.9297 Validation Accuracy: 0.320312\n",
      "Epoch  1, Batch  33 -Loss: 12265.9668 Validation Accuracy: 0.320312\n",
      "Epoch  1, Batch  34 -Loss: 11120.9736 Validation Accuracy: 0.335938\n",
      "Epoch  1, Batch  35 -Loss: 12093.6055 Validation Accuracy: 0.328125\n",
      "Epoch  1, Batch  36 -Loss: 11839.6875 Validation Accuracy: 0.328125\n",
      "Epoch  1, Batch  37 -Loss:  8958.9551 Validation Accuracy: 0.343750\n",
      "Epoch  1, Batch  38 -Loss: 10171.6113 Validation Accuracy: 0.351562\n",
      "Epoch  1, Batch  39 -Loss:  9701.4180 Validation Accuracy: 0.359375\n",
      "Epoch  1, Batch  40 -Loss:  9829.6416 Validation Accuracy: 0.359375\n",
      "Epoch  1, Batch  41 -Loss:  9151.5674 Validation Accuracy: 0.367188\n",
      "Epoch  1, Batch  42 -Loss:  9428.5469 Validation Accuracy: 0.371094\n",
      "Epoch  1, Batch  43 -Loss:  8000.0088 Validation Accuracy: 0.375000\n",
      "Epoch  1, Batch  44 -Loss:  8415.2783 Validation Accuracy: 0.390625\n",
      "Epoch  1, Batch  45 -Loss:  7716.2515 Validation Accuracy: 0.398438\n",
      "Epoch  1, Batch  46 -Loss:  8434.6074 Validation Accuracy: 0.398438\n",
      "Epoch  1, Batch  47 -Loss: 10121.9570 Validation Accuracy: 0.402344\n",
      "Epoch  1, Batch  48 -Loss:  9572.4268 Validation Accuracy: 0.406250\n",
      "Epoch  1, Batch  49 -Loss: 10742.9785 Validation Accuracy: 0.406250\n",
      "Epoch  1, Batch  50 -Loss:  8968.2100 Validation Accuracy: 0.414062\n",
      "Epoch  1, Batch  51 -Loss:  8150.9624 Validation Accuracy: 0.421875\n",
      "Epoch  1, Batch  52 -Loss:  7797.3965 Validation Accuracy: 0.429688\n",
      "Epoch  1, Batch  53 -Loss:  7181.5552 Validation Accuracy: 0.425781\n",
      "Epoch  1, Batch  54 -Loss:  7922.2886 Validation Accuracy: 0.445312\n",
      "Epoch  1, Batch  55 -Loss:  8190.0737 Validation Accuracy: 0.441406\n",
      "Epoch  1, Batch  56 -Loss:  8469.8936 Validation Accuracy: 0.437500\n",
      "Epoch  1, Batch  57 -Loss:  9591.7031 Validation Accuracy: 0.453125\n",
      "Epoch  1, Batch  58 -Loss:  6987.4800 Validation Accuracy: 0.472656\n",
      "Epoch  1, Batch  59 -Loss:  6891.4683 Validation Accuracy: 0.476562\n",
      "Epoch  1, Batch  60 -Loss:  7302.4590 Validation Accuracy: 0.464844\n",
      "Epoch  1, Batch  61 -Loss:  6495.6221 Validation Accuracy: 0.480469\n",
      "Epoch  1, Batch  62 -Loss:  6919.7114 Validation Accuracy: 0.480469\n",
      "Epoch  1, Batch  63 -Loss:  6479.0566 Validation Accuracy: 0.488281\n",
      "Epoch  1, Batch  64 -Loss:  7345.3662 Validation Accuracy: 0.488281\n",
      "Epoch  1, Batch  65 -Loss:  6780.2852 Validation Accuracy: 0.496094\n",
      "Epoch  1, Batch  66 -Loss:  7308.1299 Validation Accuracy: 0.484375\n",
      "Epoch  1, Batch  67 -Loss:  5201.6519 Validation Accuracy: 0.503906\n",
      "Epoch  1, Batch  68 -Loss:  8765.9473 Validation Accuracy: 0.492188\n",
      "Epoch  1, Batch  69 -Loss:  6957.0811 Validation Accuracy: 0.480469\n",
      "Epoch  1, Batch  70 -Loss:  5496.4180 Validation Accuracy: 0.503906\n",
      "Epoch  1, Batch  71 -Loss:  8603.5273 Validation Accuracy: 0.488281\n",
      "Epoch  1, Batch  72 -Loss:  7124.6392 Validation Accuracy: 0.484375\n",
      "Epoch  1, Batch  73 -Loss:  6892.1172 Validation Accuracy: 0.507812\n",
      "Epoch  1, Batch  74 -Loss:  6355.0469 Validation Accuracy: 0.519531\n",
      "Epoch  1, Batch  75 -Loss:  7017.4390 Validation Accuracy: 0.507812\n",
      "Epoch  1, Batch  76 -Loss:  6718.0732 Validation Accuracy: 0.500000\n",
      "Epoch  1, Batch  77 -Loss:  6153.7373 Validation Accuracy: 0.527344\n",
      "Epoch  1, Batch  78 -Loss:  7044.4248 Validation Accuracy: 0.519531\n",
      "Epoch  1, Batch  79 -Loss:  5021.0889 Validation Accuracy: 0.527344\n",
      "Epoch  1, Batch  80 -Loss:  7332.5654 Validation Accuracy: 0.535156\n",
      "Epoch  1, Batch  81 -Loss:  6369.4268 Validation Accuracy: 0.558594\n",
      "Epoch  1, Batch  82 -Loss:  3668.4512 Validation Accuracy: 0.554688\n",
      "Epoch  1, Batch  83 -Loss:  4873.5767 Validation Accuracy: 0.566406\n",
      "Epoch  1, Batch  84 -Loss:  4893.1401 Validation Accuracy: 0.535156\n",
      "Epoch  1, Batch  85 -Loss:  6762.4189 Validation Accuracy: 0.550781\n",
      "Epoch  1, Batch  86 -Loss:  4728.9287 Validation Accuracy: 0.554688\n",
      "Epoch  1, Batch  87 -Loss:  6199.2090 Validation Accuracy: 0.531250\n",
      "Epoch  1, Batch  88 -Loss:  6004.1924 Validation Accuracy: 0.546875\n",
      "Epoch  1, Batch  89 -Loss:  6254.4985 Validation Accuracy: 0.562500\n",
      "Epoch  1, Batch  90 -Loss:  6364.3413 Validation Accuracy: 0.582031\n",
      "Epoch  1, Batch  91 -Loss:  5709.1562 Validation Accuracy: 0.574219\n",
      "Epoch  1, Batch  92 -Loss:  4433.5645 Validation Accuracy: 0.570312\n",
      "Epoch  1, Batch  93 -Loss:  4151.4663 Validation Accuracy: 0.578125\n",
      "Epoch  1, Batch  94 -Loss:  5054.2803 Validation Accuracy: 0.578125\n",
      "Epoch  1, Batch  95 -Loss:  3591.3906 Validation Accuracy: 0.582031\n",
      "Epoch  1, Batch  96 -Loss:  4804.8252 Validation Accuracy: 0.574219\n",
      "Epoch  1, Batch  97 -Loss:  4528.7246 Validation Accuracy: 0.566406\n",
      "Epoch  1, Batch  98 -Loss:  5813.8882 Validation Accuracy: 0.589844\n",
      "Epoch  1, Batch  99 -Loss:  5477.8394 Validation Accuracy: 0.578125\n",
      "Epoch  1, Batch 100 -Loss:  4013.3530 Validation Accuracy: 0.578125\n",
      "Epoch  1, Batch 101 -Loss:  4555.8325 Validation Accuracy: 0.589844\n",
      "Epoch  1, Batch 102 -Loss:  4847.9233 Validation Accuracy: 0.585938\n",
      "Epoch  1, Batch 103 -Loss:  4929.9902 Validation Accuracy: 0.589844\n",
      "Epoch  1, Batch 104 -Loss:  4590.3921 Validation Accuracy: 0.582031\n",
      "Epoch  1, Batch 105 -Loss:  5368.0566 Validation Accuracy: 0.589844\n",
      "Epoch  1, Batch 106 -Loss:  4663.4517 Validation Accuracy: 0.589844\n",
      "Epoch  1, Batch 107 -Loss:  3902.9421 Validation Accuracy: 0.601562\n",
      "Epoch  1, Batch 108 -Loss:  4146.2173 Validation Accuracy: 0.597656\n",
      "Epoch  1, Batch 109 -Loss:  6032.1626 Validation Accuracy: 0.593750\n",
      "Epoch  1, Batch 110 -Loss:  6011.2109 Validation Accuracy: 0.593750\n",
      "Epoch  1, Batch 111 -Loss:  3757.9224 Validation Accuracy: 0.589844\n",
      "Epoch  1, Batch 112 -Loss:  3918.5093 Validation Accuracy: 0.589844\n",
      "Epoch  1, Batch 113 -Loss:  3876.1724 Validation Accuracy: 0.597656\n",
      "Epoch  1, Batch 114 -Loss:  4401.3223 Validation Accuracy: 0.597656\n",
      "Epoch  1, Batch 115 -Loss:  4924.6758 Validation Accuracy: 0.601562\n",
      "Epoch  1, Batch 116 -Loss:  4439.9102 Validation Accuracy: 0.609375\n",
      "Epoch  1, Batch 117 -Loss:  3708.5552 Validation Accuracy: 0.609375\n",
      "Epoch  1, Batch 118 -Loss:  4934.1792 Validation Accuracy: 0.617188\n",
      "Epoch  1, Batch 119 -Loss:  4023.9736 Validation Accuracy: 0.601562\n",
      "Epoch  1, Batch 120 -Loss:  5044.4062 Validation Accuracy: 0.605469\n",
      "Epoch  1, Batch 121 -Loss:  3211.9062 Validation Accuracy: 0.597656\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  1, Batch 122 -Loss:  5116.7720 Validation Accuracy: 0.609375\n",
      "Epoch  1, Batch 123 -Loss:  3436.7012 Validation Accuracy: 0.613281\n",
      "Epoch  1, Batch 124 -Loss:  3204.3989 Validation Accuracy: 0.609375\n",
      "Epoch  1, Batch 125 -Loss:  4998.8203 Validation Accuracy: 0.617188\n",
      "Epoch  1, Batch 126 -Loss:  5870.1826 Validation Accuracy: 0.621094\n",
      "Epoch  1, Batch 127 -Loss:  6285.7925 Validation Accuracy: 0.636719\n",
      "Epoch  1, Batch 128 -Loss:  4001.6714 Validation Accuracy: 0.632812\n",
      "Epoch  1, Batch 129 -Loss:  4092.8430 Validation Accuracy: 0.628906\n",
      "Epoch  1, Batch 130 -Loss:  4818.8208 Validation Accuracy: 0.628906\n",
      "Epoch  1, Batch 131 -Loss:  3884.9307 Validation Accuracy: 0.632812\n",
      "Epoch  1, Batch 132 -Loss:  5340.4902 Validation Accuracy: 0.625000\n",
      "Epoch  1, Batch 133 -Loss:  4615.8467 Validation Accuracy: 0.621094\n",
      "Epoch  1, Batch 134 -Loss:  3806.3633 Validation Accuracy: 0.617188\n",
      "Epoch  1, Batch 135 -Loss:  3947.0366 Validation Accuracy: 0.621094\n",
      "Epoch  1, Batch 136 -Loss:  4170.1816 Validation Accuracy: 0.621094\n",
      "Epoch  1, Batch 137 -Loss:  4077.5627 Validation Accuracy: 0.621094\n",
      "Epoch  1, Batch 138 -Loss:  3277.3403 Validation Accuracy: 0.617188\n",
      "Epoch  1, Batch 139 -Loss:  3288.9182 Validation Accuracy: 0.617188\n",
      "Epoch  1, Batch 140 -Loss:  3744.1467 Validation Accuracy: 0.621094\n",
      "Epoch  1, Batch 141 -Loss:  4818.1040 Validation Accuracy: 0.625000\n",
      "Epoch  1, Batch 142 -Loss:  4075.7888 Validation Accuracy: 0.625000\n",
      "Epoch  1, Batch 143 -Loss:  3679.8184 Validation Accuracy: 0.617188\n",
      "Epoch  1, Batch 144 -Loss:  4283.1206 Validation Accuracy: 0.621094\n",
      "Epoch  1, Batch 145 -Loss:  3745.2983 Validation Accuracy: 0.617188\n",
      "Epoch  1, Batch 146 -Loss:  4302.6572 Validation Accuracy: 0.617188\n",
      "Epoch  1, Batch 147 -Loss:  3119.4458 Validation Accuracy: 0.632812\n",
      "Epoch  1, Batch 148 -Loss:  3596.7236 Validation Accuracy: 0.640625\n",
      "Epoch  1, Batch 149 -Loss:  3331.1260 Validation Accuracy: 0.632812\n",
      "Epoch  1, Batch 150 -Loss:  4599.9595 Validation Accuracy: 0.636719\n",
      "Epoch  1, Batch 151 -Loss:  3678.7649 Validation Accuracy: 0.636719\n",
      "Epoch  1, Batch 152 -Loss:  3269.5320 Validation Accuracy: 0.640625\n",
      "Epoch  1, Batch 153 -Loss:  3599.8140 Validation Accuracy: 0.644531\n",
      "Epoch  1, Batch 154 -Loss:  4297.6592 Validation Accuracy: 0.632812\n",
      "Epoch  1, Batch 155 -Loss:  3095.1846 Validation Accuracy: 0.636719\n",
      "Epoch  1, Batch 156 -Loss:  3475.8975 Validation Accuracy: 0.636719\n",
      "Epoch  1, Batch 157 -Loss:  3693.1753 Validation Accuracy: 0.628906\n",
      "Epoch  1, Batch 158 -Loss:  2666.9207 Validation Accuracy: 0.636719\n",
      "Epoch  1, Batch 159 -Loss:  3246.8569 Validation Accuracy: 0.632812\n",
      "Epoch  1, Batch 160 -Loss:  2896.9946 Validation Accuracy: 0.640625\n",
      "Epoch  1, Batch 161 -Loss:  3336.8081 Validation Accuracy: 0.628906\n",
      "Epoch  1, Batch 162 -Loss:  4037.6274 Validation Accuracy: 0.632812\n",
      "Epoch  1, Batch 163 -Loss:  2955.4814 Validation Accuracy: 0.640625\n",
      "Epoch  1, Batch 164 -Loss:  3011.5398 Validation Accuracy: 0.640625\n",
      "Epoch  1, Batch 165 -Loss:  2691.9141 Validation Accuracy: 0.632812\n",
      "Epoch  1, Batch 166 -Loss:  3350.8008 Validation Accuracy: 0.632812\n",
      "Epoch  1, Batch 167 -Loss:  3977.7896 Validation Accuracy: 0.632812\n",
      "Epoch  1, Batch 168 -Loss:  2618.5691 Validation Accuracy: 0.640625\n",
      "Epoch  1, Batch 169 -Loss:  2641.4131 Validation Accuracy: 0.636719\n",
      "Epoch  1, Batch 170 -Loss:  2700.2400 Validation Accuracy: 0.640625\n",
      "Epoch  1, Batch 171 -Loss:  3833.4355 Validation Accuracy: 0.648438\n",
      "Epoch  1, Batch 172 -Loss:  2778.9624 Validation Accuracy: 0.644531\n",
      "Epoch  1, Batch 173 -Loss:  2942.4009 Validation Accuracy: 0.648438\n",
      "Epoch  1, Batch 174 -Loss:  4525.1836 Validation Accuracy: 0.640625\n",
      "Epoch  1, Batch 175 -Loss:  3567.6895 Validation Accuracy: 0.656250\n",
      "Epoch  1, Batch 176 -Loss:  3666.0762 Validation Accuracy: 0.644531\n",
      "Epoch  1, Batch 177 -Loss:  3321.5928 Validation Accuracy: 0.640625\n",
      "Epoch  1, Batch 178 -Loss:  2970.8804 Validation Accuracy: 0.644531\n",
      "Epoch  1, Batch 179 -Loss:  3318.8442 Validation Accuracy: 0.640625\n",
      "Epoch  1, Batch 180 -Loss:  2303.7036 Validation Accuracy: 0.660156\n",
      "Epoch  1, Batch 181 -Loss:  3331.8757 Validation Accuracy: 0.652344\n",
      "Epoch  1, Batch 182 -Loss:  2489.9448 Validation Accuracy: 0.656250\n",
      "Epoch  1, Batch 183 -Loss:  2205.1541 Validation Accuracy: 0.656250\n",
      "Epoch  1, Batch 184 -Loss:  2574.7190 Validation Accuracy: 0.664062\n",
      "Epoch  1, Batch 185 -Loss:  2652.6333 Validation Accuracy: 0.664062\n",
      "Epoch  1, Batch 186 -Loss:  3155.2937 Validation Accuracy: 0.667969\n",
      "Epoch  1, Batch 187 -Loss:  3863.8882 Validation Accuracy: 0.652344\n",
      "Epoch  1, Batch 188 -Loss:  3429.9946 Validation Accuracy: 0.664062\n",
      "Epoch  1, Batch 189 -Loss:  4125.9150 Validation Accuracy: 0.664062\n",
      "Epoch  1, Batch 190 -Loss:  2580.3091 Validation Accuracy: 0.667969\n",
      "Epoch  1, Batch 191 -Loss:  2394.9189 Validation Accuracy: 0.675781\n",
      "Epoch  1, Batch 192 -Loss:  3476.8154 Validation Accuracy: 0.683594\n",
      "Epoch  1, Batch 193 -Loss:  3497.8730 Validation Accuracy: 0.687500\n",
      "Epoch  1, Batch 194 -Loss:  3078.6121 Validation Accuracy: 0.664062\n",
      "Epoch  1, Batch 195 -Loss:  3318.3296 Validation Accuracy: 0.691406\n",
      "Epoch  1, Batch 196 -Loss:  4026.8560 Validation Accuracy: 0.687500\n",
      "Epoch  1, Batch 197 -Loss:  2971.4229 Validation Accuracy: 0.675781\n",
      "Epoch  1, Batch 198 -Loss:  3671.6562 Validation Accuracy: 0.679688\n",
      "Epoch  1, Batch 199 -Loss:  2602.2271 Validation Accuracy: 0.679688\n",
      "Epoch  1, Batch 200 -Loss:  3380.9048 Validation Accuracy: 0.687500\n",
      "Epoch  1, Batch 201 -Loss:  2916.5034 Validation Accuracy: 0.683594\n",
      "Epoch  1, Batch 202 -Loss:  2536.3103 Validation Accuracy: 0.683594\n",
      "Epoch  1, Batch 203 -Loss:  3549.6929 Validation Accuracy: 0.671875\n",
      "Epoch  1, Batch 204 -Loss:  3096.1147 Validation Accuracy: 0.679688\n",
      "Epoch  1, Batch 205 -Loss:  2334.6807 Validation Accuracy: 0.687500\n",
      "Epoch  1, Batch 206 -Loss:  2731.7288 Validation Accuracy: 0.691406\n",
      "Epoch  1, Batch 207 -Loss:  2821.7222 Validation Accuracy: 0.691406\n",
      "Epoch  1, Batch 208 -Loss:  3519.4253 Validation Accuracy: 0.679688\n",
      "Epoch  1, Batch 209 -Loss:  3290.7664 Validation Accuracy: 0.683594\n",
      "Epoch  1, Batch 210 -Loss:  3033.2288 Validation Accuracy: 0.660156\n",
      "Epoch  1, Batch 211 -Loss:  3200.1162 Validation Accuracy: 0.683594\n",
      "Epoch  1, Batch 212 -Loss:  2107.4309 Validation Accuracy: 0.691406\n",
      "Epoch  1, Batch 213 -Loss:  2585.6099 Validation Accuracy: 0.683594\n",
      "Epoch  1, Batch 214 -Loss:  2984.5786 Validation Accuracy: 0.687500\n",
      "Epoch  1, Batch 215 -Loss:  2583.6328 Validation Accuracy: 0.691406\n",
      "Epoch  1, Batch 216 -Loss:  2835.3394 Validation Accuracy: 0.691406\n",
      "Epoch  1, Batch 217 -Loss:  2628.4111 Validation Accuracy: 0.695312\n",
      "Epoch  1, Batch 218 -Loss:  2572.7373 Validation Accuracy: 0.699219\n",
      "Epoch  1, Batch 219 -Loss:  3157.6836 Validation Accuracy: 0.703125\n",
      "Epoch  1, Batch 220 -Loss:  2352.5459 Validation Accuracy: 0.699219\n",
      "Epoch  1, Batch 221 -Loss:  3251.5842 Validation Accuracy: 0.699219\n",
      "Epoch  1, Batch 222 -Loss:  2819.3884 Validation Accuracy: 0.707031\n",
      "Epoch  1, Batch 223 -Loss:  2478.1968 Validation Accuracy: 0.707031\n",
      "Epoch  1, Batch 224 -Loss:  2849.9951 Validation Accuracy: 0.703125\n",
      "Epoch  1, Batch 225 -Loss:  1998.5696 Validation Accuracy: 0.710938\n",
      "Epoch  1, Batch 226 -Loss:  2261.6553 Validation Accuracy: 0.710938\n",
      "Epoch  1, Batch 227 -Loss:  3363.8328 Validation Accuracy: 0.703125\n",
      "Epoch  1, Batch 228 -Loss:  2586.5767 Validation Accuracy: 0.703125\n",
      "Epoch  1, Batch 229 -Loss:  2972.4497 Validation Accuracy: 0.703125\n",
      "Epoch  1, Batch 230 -Loss:  1696.2097 Validation Accuracy: 0.695312\n",
      "Epoch  1, Batch 231 -Loss:  2488.3452 Validation Accuracy: 0.710938\n",
      "Epoch  1, Batch 232 -Loss:  2363.5957 Validation Accuracy: 0.714844\n",
      "Epoch  1, Batch 233 -Loss:  3097.9888 Validation Accuracy: 0.703125\n",
      "Epoch  1, Batch 234 -Loss:  2418.8862 Validation Accuracy: 0.707031\n",
      "Epoch  1, Batch 235 -Loss:  2924.2820 Validation Accuracy: 0.710938\n",
      "Epoch  1, Batch 236 -Loss:  2013.8760 Validation Accuracy: 0.710938\n",
      "Epoch  1, Batch 237 -Loss:  2585.4478 Validation Accuracy: 0.714844\n",
      "Epoch  1, Batch 238 -Loss:  2343.5320 Validation Accuracy: 0.718750\n",
      "Epoch  1, Batch 239 -Loss:  2535.1458 Validation Accuracy: 0.718750\n",
      "Epoch  1, Batch 240 -Loss:  2391.7505 Validation Accuracy: 0.714844\n",
      "Epoch  1, Batch 241 -Loss:  2810.7209 Validation Accuracy: 0.710938\n",
      "Epoch  1, Batch 242 -Loss:  2189.2034 Validation Accuracy: 0.699219\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  1, Batch 243 -Loss:  2671.0732 Validation Accuracy: 0.703125\n",
      "Epoch  1, Batch 244 -Loss:  2672.9893 Validation Accuracy: 0.707031\n",
      "Epoch  1, Batch 245 -Loss:  2519.7837 Validation Accuracy: 0.699219\n",
      "Epoch  1, Batch 246 -Loss:  2388.9316 Validation Accuracy: 0.703125\n",
      "Epoch  1, Batch 247 -Loss:  2532.7957 Validation Accuracy: 0.710938\n",
      "Epoch  1, Batch 248 -Loss:  2622.2739 Validation Accuracy: 0.718750\n",
      "Epoch  1, Batch 249 -Loss:  2185.5598 Validation Accuracy: 0.726562\n",
      "Epoch  1, Batch 250 -Loss:  2459.4487 Validation Accuracy: 0.710938\n",
      "Epoch  1, Batch 251 -Loss:  2719.8506 Validation Accuracy: 0.722656\n",
      "Epoch  1, Batch 252 -Loss:  2295.7671 Validation Accuracy: 0.726562\n",
      "Epoch  1, Batch 253 -Loss:  1981.0527 Validation Accuracy: 0.718750\n",
      "Epoch  1, Batch 254 -Loss:  2304.9658 Validation Accuracy: 0.722656\n",
      "Epoch  1, Batch 255 -Loss:  2074.7124 Validation Accuracy: 0.722656\n",
      "Epoch  1, Batch 256 -Loss:  2690.4863 Validation Accuracy: 0.714844\n",
      "Epoch  1, Batch 257 -Loss:  3053.3667 Validation Accuracy: 0.710938\n",
      "Epoch  1, Batch 258 -Loss:  2011.6824 Validation Accuracy: 0.710938\n",
      "Epoch  1, Batch 259 -Loss:  2435.9729 Validation Accuracy: 0.714844\n",
      "Epoch  1, Batch 260 -Loss:  2163.2578 Validation Accuracy: 0.714844\n",
      "Epoch  1, Batch 261 -Loss:  2419.0566 Validation Accuracy: 0.714844\n",
      "Epoch  1, Batch 262 -Loss:  2724.6116 Validation Accuracy: 0.710938\n",
      "Epoch  1, Batch 263 -Loss:  2786.8281 Validation Accuracy: 0.707031\n",
      "Epoch  1, Batch 264 -Loss:  1775.0255 Validation Accuracy: 0.707031\n",
      "Epoch  1, Batch 265 -Loss:  2026.1785 Validation Accuracy: 0.707031\n",
      "Epoch  1, Batch 266 -Loss:  2675.7368 Validation Accuracy: 0.710938\n",
      "Epoch  1, Batch 267 -Loss:  3050.5759 Validation Accuracy: 0.707031\n",
      "Epoch  1, Batch 268 -Loss:  1877.0396 Validation Accuracy: 0.703125\n",
      "Epoch  1, Batch 269 -Loss:  2633.1069 Validation Accuracy: 0.703125\n",
      "Epoch  1, Batch 270 -Loss:  1774.3623 Validation Accuracy: 0.695312\n",
      "Epoch  1, Batch 271 -Loss:  1789.7943 Validation Accuracy: 0.695312\n",
      "Epoch  1, Batch 272 -Loss:  2580.1777 Validation Accuracy: 0.699219\n",
      "Epoch  1, Batch 273 -Loss:  2473.6863 Validation Accuracy: 0.703125\n",
      "Epoch  1, Batch 274 -Loss:  2335.1335 Validation Accuracy: 0.707031\n",
      "Epoch  1, Batch 275 -Loss:  2421.9580 Validation Accuracy: 0.703125\n",
      "Epoch  1, Batch 276 -Loss:  3228.3286 Validation Accuracy: 0.710938\n",
      "Epoch  1, Batch 277 -Loss:  2072.2122 Validation Accuracy: 0.710938\n",
      "Epoch  1, Batch 278 -Loss:  2251.8293 Validation Accuracy: 0.714844\n",
      "Epoch  1, Batch 279 -Loss:  2886.2639 Validation Accuracy: 0.703125\n",
      "Epoch  1, Batch 280 -Loss:  3402.2954 Validation Accuracy: 0.703125\n",
      "Epoch  1, Batch 281 -Loss:  2123.1245 Validation Accuracy: 0.703125\n",
      "Epoch  1, Batch 282 -Loss:  1807.8561 Validation Accuracy: 0.703125\n",
      "Epoch  1, Batch 283 -Loss:  1736.2013 Validation Accuracy: 0.699219\n",
      "Epoch  1, Batch 284 -Loss:  2229.2769 Validation Accuracy: 0.695312\n",
      "Epoch  1, Batch 285 -Loss:  2478.2290 Validation Accuracy: 0.703125\n",
      "Epoch  1, Batch 286 -Loss:  2265.7964 Validation Accuracy: 0.703125\n",
      "Epoch  1, Batch 287 -Loss:  2089.8164 Validation Accuracy: 0.707031\n",
      "Epoch  1, Batch 288 -Loss:  1397.3478 Validation Accuracy: 0.710938\n",
      "Epoch  1, Batch 289 -Loss:  2865.8286 Validation Accuracy: 0.710938\n",
      "Epoch  1, Batch 290 -Loss:  1559.7725 Validation Accuracy: 0.710938\n",
      "Epoch  1, Batch 291 -Loss:  2349.2830 Validation Accuracy: 0.699219\n",
      "Epoch  1, Batch 292 -Loss:  2090.5713 Validation Accuracy: 0.707031\n",
      "Epoch  1, Batch 293 -Loss:  2131.8323 Validation Accuracy: 0.714844\n",
      "Epoch  1, Batch 294 -Loss:  2153.6753 Validation Accuracy: 0.707031\n",
      "Epoch  1, Batch 295 -Loss:  2259.9348 Validation Accuracy: 0.710938\n",
      "Epoch  1, Batch 296 -Loss:  1954.7241 Validation Accuracy: 0.714844\n",
      "Epoch  1, Batch 297 -Loss:  2968.5000 Validation Accuracy: 0.714844\n",
      "Epoch  1, Batch 298 -Loss:  2297.0483 Validation Accuracy: 0.718750\n",
      "Epoch  1, Batch 299 -Loss:  1538.8960 Validation Accuracy: 0.714844\n",
      "Epoch  1, Batch 300 -Loss:  2137.3469 Validation Accuracy: 0.710938\n",
      "Epoch  1, Batch 301 -Loss:  1601.1870 Validation Accuracy: 0.710938\n",
      "Epoch  1, Batch 302 -Loss:  2420.4917 Validation Accuracy: 0.718750\n",
      "Epoch  1, Batch 303 -Loss:  2204.4663 Validation Accuracy: 0.714844\n",
      "Epoch  1, Batch 304 -Loss:  1754.0038 Validation Accuracy: 0.718750\n",
      "Epoch  1, Batch 305 -Loss:  1690.2439 Validation Accuracy: 0.718750\n",
      "Epoch  1, Batch 306 -Loss:  2277.8755 Validation Accuracy: 0.718750\n",
      "Epoch  1, Batch 307 -Loss:  2194.4814 Validation Accuracy: 0.710938\n",
      "Epoch  1, Batch 308 -Loss:  2331.9561 Validation Accuracy: 0.710938\n",
      "Epoch  1, Batch 309 -Loss:  2515.8926 Validation Accuracy: 0.714844\n",
      "Epoch  1, Batch 310 -Loss:  2341.8596 Validation Accuracy: 0.722656\n",
      "Epoch  1, Batch 311 -Loss:  2645.9829 Validation Accuracy: 0.718750\n",
      "Epoch  1, Batch 312 -Loss:  2665.0117 Validation Accuracy: 0.714844\n",
      "Epoch  1, Batch 313 -Loss:  1906.0642 Validation Accuracy: 0.707031\n",
      "Epoch  1, Batch 314 -Loss:  2666.6853 Validation Accuracy: 0.699219\n",
      "Epoch  1, Batch 315 -Loss:  1922.5979 Validation Accuracy: 0.703125\n",
      "Epoch  1, Batch 316 -Loss:  3501.1030 Validation Accuracy: 0.703125\n",
      "Epoch  1, Batch 317 -Loss:  2387.1094 Validation Accuracy: 0.710938\n",
      "Epoch  1, Batch 318 -Loss:  1795.3906 Validation Accuracy: 0.710938\n",
      "Epoch  1, Batch 319 -Loss:  2158.0684 Validation Accuracy: 0.707031\n",
      "Epoch  1, Batch 320 -Loss:  1718.4552 Validation Accuracy: 0.707031\n",
      "Epoch  1, Batch 321 -Loss:  1816.8530 Validation Accuracy: 0.699219\n",
      "Epoch  1, Batch 322 -Loss:  2347.9888 Validation Accuracy: 0.687500\n",
      "Epoch  1, Batch 323 -Loss:  1968.0676 Validation Accuracy: 0.687500\n",
      "Epoch  1, Batch 324 -Loss:  1831.4257 Validation Accuracy: 0.687500\n",
      "Epoch  1, Batch 325 -Loss:  1890.8467 Validation Accuracy: 0.703125\n",
      "Epoch  1, Batch 326 -Loss:  1909.4766 Validation Accuracy: 0.695312\n",
      "Epoch  1, Batch 327 -Loss:  2911.2917 Validation Accuracy: 0.691406\n",
      "Epoch  1, Batch 328 -Loss:  2632.0029 Validation Accuracy: 0.699219\n",
      "Epoch  1, Batch 329 -Loss:  2341.0439 Validation Accuracy: 0.703125\n",
      "Epoch  1, Batch 330 -Loss:  1908.5188 Validation Accuracy: 0.714844\n",
      "Epoch  1, Batch 331 -Loss:  1685.3827 Validation Accuracy: 0.714844\n",
      "Epoch  1, Batch 332 -Loss:  2417.8628 Validation Accuracy: 0.707031\n",
      "Epoch  1, Batch 333 -Loss:  1525.6289 Validation Accuracy: 0.714844\n",
      "Epoch  1, Batch 334 -Loss:  1799.7889 Validation Accuracy: 0.707031\n",
      "Epoch  1, Batch 335 -Loss:  2944.8862 Validation Accuracy: 0.718750\n",
      "Epoch  1, Batch 336 -Loss:  1694.1056 Validation Accuracy: 0.714844\n",
      "Epoch  1, Batch 337 -Loss:  2473.9851 Validation Accuracy: 0.714844\n",
      "Epoch  1, Batch 338 -Loss:  2005.3201 Validation Accuracy: 0.718750\n",
      "Epoch  1, Batch 339 -Loss:  2041.4156 Validation Accuracy: 0.714844\n",
      "Epoch  1, Batch 340 -Loss:  1892.5181 Validation Accuracy: 0.707031\n",
      "Epoch  1, Batch 341 -Loss:  1939.2839 Validation Accuracy: 0.707031\n",
      "Epoch  1, Batch 342 -Loss:  1702.2554 Validation Accuracy: 0.714844\n",
      "Epoch  1, Batch 343 -Loss:  2437.6797 Validation Accuracy: 0.714844\n",
      "Epoch  1, Batch 344 -Loss:  1225.9233 Validation Accuracy: 0.703125\n",
      "Epoch  1, Batch 345 -Loss:  2311.7725 Validation Accuracy: 0.707031\n",
      "Epoch  1, Batch 346 -Loss:  2275.8726 Validation Accuracy: 0.710938\n",
      "Epoch  1, Batch 347 -Loss:  1794.3199 Validation Accuracy: 0.703125\n",
      "Epoch  1, Batch 348 -Loss:  1900.9111 Validation Accuracy: 0.699219\n",
      "Epoch  1, Batch 349 -Loss:  2777.8545 Validation Accuracy: 0.695312\n",
      "Epoch  1, Batch 350 -Loss:  2556.0020 Validation Accuracy: 0.695312\n",
      "Epoch  1, Batch 351 -Loss:  1851.5255 Validation Accuracy: 0.699219\n",
      "Epoch  1, Batch 352 -Loss:  2626.9399 Validation Accuracy: 0.707031\n",
      "Epoch  1, Batch 353 -Loss:  1902.0840 Validation Accuracy: 0.714844\n",
      "Epoch  1, Batch 354 -Loss:  2078.1807 Validation Accuracy: 0.718750\n",
      "Epoch  1, Batch 355 -Loss:  1892.6858 Validation Accuracy: 0.714844\n",
      "Epoch  1, Batch 356 -Loss:  2711.4175 Validation Accuracy: 0.710938\n",
      "Epoch  1, Batch 357 -Loss:  1714.5508 Validation Accuracy: 0.718750\n",
      "Epoch  1, Batch 358 -Loss:  2230.0469 Validation Accuracy: 0.714844\n",
      "Epoch  1, Batch 359 -Loss:  1368.2461 Validation Accuracy: 0.714844\n",
      "Epoch  1, Batch 360 -Loss:  2036.9974 Validation Accuracy: 0.718750\n",
      "Epoch  1, Batch 361 -Loss:  2303.8330 Validation Accuracy: 0.714844\n",
      "Epoch  1, Batch 362 -Loss:  2118.1741 Validation Accuracy: 0.718750\n",
      "Epoch  1, Batch 363 -Loss:  2472.8120 Validation Accuracy: 0.707031\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  1, Batch 364 -Loss:  2140.2930 Validation Accuracy: 0.699219\n",
      "Epoch  1, Batch 365 -Loss:  2628.9990 Validation Accuracy: 0.707031\n",
      "Epoch  1, Batch 366 -Loss:  1678.2190 Validation Accuracy: 0.710938\n",
      "Epoch  1, Batch 367 -Loss:  1917.7104 Validation Accuracy: 0.710938\n",
      "Epoch  1, Batch 368 -Loss:  1931.7659 Validation Accuracy: 0.707031\n",
      "Epoch  1, Batch 369 -Loss:  1586.5148 Validation Accuracy: 0.707031\n",
      "Epoch  1, Batch 370 -Loss:  1423.8953 Validation Accuracy: 0.707031\n",
      "Epoch  1, Batch 371 -Loss:  2086.1450 Validation Accuracy: 0.707031\n",
      "Epoch  1, Batch 372 -Loss:  2236.9971 Validation Accuracy: 0.703125\n",
      "Epoch  1, Batch 373 -Loss:  1950.5381 Validation Accuracy: 0.703125\n",
      "Epoch  1, Batch 374 -Loss:  2693.3289 Validation Accuracy: 0.707031\n",
      "Epoch  1, Batch 375 -Loss:  2661.0176 Validation Accuracy: 0.714844\n",
      "Epoch  1, Batch 376 -Loss:  2150.5991 Validation Accuracy: 0.714844\n",
      "Epoch  1, Batch 377 -Loss:  1796.4341 Validation Accuracy: 0.710938\n",
      "Epoch  1, Batch 378 -Loss:  1823.5459 Validation Accuracy: 0.707031\n",
      "Epoch  1, Batch 379 -Loss:  2031.3301 Validation Accuracy: 0.710938\n",
      "Epoch  1, Batch 380 -Loss:  1745.3387 Validation Accuracy: 0.718750\n",
      "Epoch  1, Batch 381 -Loss:  1877.4111 Validation Accuracy: 0.710938\n",
      "Epoch  1, Batch 382 -Loss:  2290.1653 Validation Accuracy: 0.710938\n",
      "Epoch  1, Batch 383 -Loss:  1873.7504 Validation Accuracy: 0.707031\n",
      "Epoch  1, Batch 384 -Loss:  2256.7432 Validation Accuracy: 0.707031\n",
      "Epoch  1, Batch 385 -Loss:  1975.0665 Validation Accuracy: 0.703125\n",
      "Epoch  1, Batch 386 -Loss:  1743.9768 Validation Accuracy: 0.710938\n",
      "Epoch  1, Batch 387 -Loss:  1650.8513 Validation Accuracy: 0.703125\n",
      "Epoch  1, Batch 388 -Loss:  1706.4229 Validation Accuracy: 0.710938\n",
      "Epoch  1, Batch 389 -Loss:  2252.2087 Validation Accuracy: 0.707031\n",
      "Epoch  1, Batch 390 -Loss:  1923.8981 Validation Accuracy: 0.707031\n",
      "Epoch  1, Batch 391 -Loss:  1733.7722 Validation Accuracy: 0.707031\n",
      "Epoch  1, Batch 392 -Loss:  1416.1531 Validation Accuracy: 0.710938\n",
      "Epoch  1, Batch 393 -Loss:  1587.3977 Validation Accuracy: 0.699219\n",
      "Epoch  1, Batch 394 -Loss:  1839.1693 Validation Accuracy: 0.710938\n",
      "Epoch  1, Batch 395 -Loss:  1746.6973 Validation Accuracy: 0.699219\n",
      "Epoch  1, Batch 396 -Loss:  2026.7091 Validation Accuracy: 0.703125\n",
      "Epoch  1, Batch 397 -Loss:  1940.6979 Validation Accuracy: 0.699219\n",
      "Epoch  1, Batch 398 -Loss:  1738.8771 Validation Accuracy: 0.703125\n",
      "Epoch  1, Batch 399 -Loss:  1851.8447 Validation Accuracy: 0.707031\n",
      "Epoch  1, Batch 400 -Loss:   977.3995 Validation Accuracy: 0.707031\n",
      "Epoch  1, Batch 401 -Loss:  1502.8120 Validation Accuracy: 0.714844\n",
      "Epoch  1, Batch 402 -Loss:  2607.8572 Validation Accuracy: 0.718750\n",
      "Epoch  1, Batch 403 -Loss:  2032.6882 Validation Accuracy: 0.714844\n",
      "Epoch  1, Batch 404 -Loss:  1445.9637 Validation Accuracy: 0.710938\n",
      "Epoch  1, Batch 405 -Loss:  1658.4961 Validation Accuracy: 0.710938\n",
      "Epoch  1, Batch 406 -Loss:  1954.8859 Validation Accuracy: 0.707031\n",
      "Epoch  1, Batch 407 -Loss:  2508.8740 Validation Accuracy: 0.710938\n",
      "Epoch  1, Batch 408 -Loss:  1786.8617 Validation Accuracy: 0.707031\n",
      "Epoch  1, Batch 409 -Loss:  1360.9319 Validation Accuracy: 0.707031\n",
      "Epoch  1, Batch 410 -Loss:  1420.0995 Validation Accuracy: 0.710938\n",
      "Epoch  1, Batch 411 -Loss:  1420.8181 Validation Accuracy: 0.714844\n",
      "Epoch  1, Batch 412 -Loss:  1562.5735 Validation Accuracy: 0.718750\n",
      "Epoch  1, Batch 413 -Loss:  1475.6577 Validation Accuracy: 0.714844\n",
      "Epoch  1, Batch 414 -Loss:  1986.5410 Validation Accuracy: 0.722656\n",
      "Epoch  1, Batch 415 -Loss:  1598.3167 Validation Accuracy: 0.718750\n",
      "Epoch  1, Batch 416 -Loss:  2256.6040 Validation Accuracy: 0.718750\n",
      "Epoch  1, Batch 417 -Loss:  2082.5164 Validation Accuracy: 0.714844\n",
      "Epoch  1, Batch 418 -Loss:  1599.9026 Validation Accuracy: 0.718750\n",
      "Epoch  1, Batch 419 -Loss:  2260.0498 Validation Accuracy: 0.722656\n",
      "Epoch  1, Batch 420 -Loss:  2116.3733 Validation Accuracy: 0.718750\n",
      "Epoch  1, Batch 421 -Loss:  1133.5173 Validation Accuracy: 0.722656\n",
      "Epoch  1, Batch 422 -Loss:  1864.0486 Validation Accuracy: 0.718750\n",
      "Epoch  1, Batch 423 -Loss:  1803.2842 Validation Accuracy: 0.714844\n",
      "Epoch  1, Batch 424 -Loss:  1589.1250 Validation Accuracy: 0.722656\n",
      "Epoch  1, Batch 425 -Loss:  1631.5283 Validation Accuracy: 0.714844\n",
      "Epoch  1, Batch 426 -Loss:  1205.5383 Validation Accuracy: 0.714844\n",
      "Epoch  1, Batch 427 -Loss:  1019.3953 Validation Accuracy: 0.722656\n",
      "Epoch  1, Batch 428 -Loss:   962.5095 Validation Accuracy: 0.722656\n",
      "Epoch  1, Batch 429 -Loss:  1624.5015 Validation Accuracy: 0.722656\n",
      "Testing Accuracy: 0.69921875\n"
     ]
    }
   ],
   "source": [
    "# tf Graph input\n",
    "\n",
    "x = tf.placeholder(tf.float32, [None, 28, 28, 1])\n",
    "y = tf.placeholder(tf.float32, [None, n_classes])\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "# Model\n",
    "logits = conv_net(x, weights, biases, keep_prob)\n",
    "# Define loss and optimizer\n",
    "cost = tf.reduce_mean(\\\n",
    "    tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=y))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\\\n",
    "    .minimize(cost)\n",
    "# Accuracy\n",
    "correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "# Initializing the variables\n",
    "init = tf. global_variables_initializer()\n",
    "# Launch the graph\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for epoch in range(epochs):\n",
    "        for batch in range(mnist.train.num_examples//batch_size):\n",
    "            batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "            sess.run(optimizer, feed_dict={\n",
    "                x: batch_x,\n",
    "                y: batch_y,\n",
    "                keep_prob: dropout})\n",
    "# Calculate batch loss and accuracy\n",
    "            loss = sess.run(cost, feed_dict={\n",
    "                x: batch_x,\n",
    "                y: batch_y,\n",
    "                keep_prob: 1.})\n",
    "            valid_acc = sess.run(accuracy, feed_dict={\n",
    "                x: mnist.validation.images[:test_valid_size],\n",
    "                y: mnist.validation.labels[:test_valid_size],\n",
    "                keep_prob: 1.})\n",
    "            print('Epoch {:>2}, Batch {:>3} -'\n",
    "                'Loss: {:>10.4f} Validation Accuracy: {:.6f}'.format(\n",
    "            epoch + 1,\n",
    "            batch + 1,\n",
    "            loss,\n",
    "            valid_acc))\n",
    "# Calculate Test Accuracy\n",
    "    test_acc = sess.run(accuracy, feed_dict={\n",
    "        x: mnist.test.images[:test_valid_size],\n",
    "        y: mnist.test.labels[:test_valid_size],\n",
    "        keep_prob: 1.})\n",
    "    print('Testing Accuracy: {}'.format(test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can further improve the accuracy by increasing the epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
